{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Decision Tree\n",
    "\n",
    "each item has two continuous features\n",
    "class label is {0, 1}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['x1', 'x2'], dtype='object')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "df = pd.read_csv('./data/D1.txt', sep='\\s+', names=['x1', 'x2', 'y'])\n",
    "df.columns[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_candidate_numeric_splits(D: pd.DataFrame, X: str) -> (str, float):\n",
    "    C = []\n",
    "    instances = D.sort_values(by=X)\n",
    "    instances = instances.reset_index(drop=True)\n",
    "    for i, row in instances.iterrows():\n",
    "        if i < len(instances) - 1:\n",
    "            y_i = row['y']\n",
    "            y_next = instances.at[i + 1, 'y']\n",
    "            if y_i != y_next:\n",
    "                x_i = row[X]\n",
    "                x_next = instances.at[i + 1, X]\n",
    "                C.append((X, x_i)) # x_i >= c\n",
    "                # C.append((X, (x_i + x_next) / 2))\n",
    "    return C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_candidate_splits(D: pd.DataFrame) -> (str, float):\n",
    "    C = []\n",
    "    for feature in D.columns[:-1]:\n",
    "        C.append(determine_candidate_numeric_splits(D, feature))\n",
    "    return C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GainRatio(D, Split) = (H(Y) - H(Y | Split)) / H(Split)\n",
    "\n",
    "def entropy_Y(D: pd.DataFrame, Y: str) -> float:\n",
    "    # H(Y) = -Sum(P(y)*log2(P(y)) for each y in Y)\n",
    "    H = 0\n",
    "    y = D[Y].unique()\n",
    "    for y_i in y:\n",
    "        Py_i = sum(D[Y] == y_i) / len(D[Y])\n",
    "        H += Py_i * math.log2(Py_i)\n",
    "    H *= -1\n",
    "    return H\n",
    "\n",
    "def entropy_S(D: pd.DataFrame, S: (str, float)) -> float:\n",
    "    H = 0\n",
    "    X, c = S\n",
    "    Pgreater = sum(D[X] >= c) / len(D[X])\n",
    "    H += Pgreater * math.log2(Pgreater)\n",
    "    Plesser = sum(D[X] < c) / len(D[X])\n",
    "    H += Plesser * math.log2(Plesser)\n",
    "    H *= -1\n",
    "    return H\n",
    "\n",
    "def conditional_entropy(D: pd.DataFrame, Y: str, S: (str, float)) -> float:\n",
    "    # H(Y | Split) = (P(X >= c) * H(Y | X >= c)) + (P(X < c) * H(Y | X < c))\n",
    "    H = 0\n",
    "    X, c = S\n",
    "    HYgreater = entropy_Y(D[D[X] >= c], Y)\n",
    "    Pgreater = sum(D[X] >= c) / len(D[X])\n",
    "    HYlesser = entropy_Y(D[D[X] < c], Y)\n",
    "    Plesser = sum(D[X] < c) / len(D[X])\n",
    "    H += Pgreater * HYgreater\n",
    "    H += Plesser * HYlesser\n",
    "    return H\n",
    "\n",
    "#print(entropy_Y(df, 'y'))\n",
    "#print(entropy_S(df, ('x1', .5)))\n",
    "#print(conditional_entropy(df, 'y', ('x2', .2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_subtree(D: pd.DataFrame):\n",
    "    stop = False\n",
    "    best_split = None\n",
    "\n",
    "    # if node is empty or all splits have 0 info or any split has 0 entropy\n",
    "    if len(D) == 0:\n",
    "        stop = True\n",
    "    else:\n",
    "        candidate_splits = determine_candidate_splits(D)\n",
    "        gainRatios = pd.Series()\n",
    "        for split in candidate_splits:\n",
    "            split_entropy = entropy_S(D, split)\n",
    "            if split_entropy == 0:\n",
    "                stop = True ##\n",
    "                break\n",
    "            else:\n",
    "                # GainRatio(D, Split) = (H(Y) - H(Y | Split)) / H(Split)\n",
    "                gainRatio = (entropy_Y(D, 'y') - conditional_entropy(D, 'y', split)) / entropy_S(D, split)\n",
    "                gainRatios.append(gainRatio)\n",
    "        best_split = candidate_splits[gainRatios.idxmax()]\n",
    "\n",
    "    if stop:\n",
    "        # make leaf node with class label\n",
    "    else:\n",
    "        # make internal node with best split\n",
    "        # create children\n",
    "            \n",
    "    # if stopping criteria:\n",
    "    #   make a leaf node N\n",
    "    #   determine class label of N\n",
    "    # else:\n",
    "    #   make internal node N\n",
    "    #   S = FindBestSplit(D, candidate_splits)\n",
    "    #   for each group k of S\n",
    "    #       Dk := subset of training data in group k\n",
    "    #       kth child of N := make_subtree(Dk)\n",
    "    # return subtree rooted at N\n",
    "    return\n",
    "\n",
    "dtree = make_subtree(df[:])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
